This repository accompanies our research paper "From SAM to DINOv2: Towards Distilling Foundation Models to Lightweight Baselines for Generalized Polyp Segmentation", where we propose a foundation-model distillation framework that transfers semantic priors from large models (SAM, CLIP, DINOv2) into compact U-Net based architectures for medical image segmentation.

üîç Highlights

Distillation from Segment Anything (SAM), DINOv2 and other foundation models. 

Lightweight segmentation baselines (U-Net, Unet ++, PraNet etc.)

Plug-and-play distillation blocks (low and high-level)

Generalized across multiple polyp datasets

Reduced training cost + improved segmentation performance of lightweight baselines

üß† Key Contributions

Two-stage knowledge distillation pipeline

Feature priors from foundation models

Low + high frequency information learning

Generalized Polyp Segmentation benchmark

