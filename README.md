This repository accompanies our research paper "From SAM to DINOv2: Towards Distilling Foundation Models to Lightweight Baselines for Generalized Polyp Segmentation", where we propose a foundation-model distillation framework that transfers semantic priors from large models (SAM, CLIP, DINOv2) into compact U-Net based architectures for medical image segmentation.

üîç Highlights

Distillation from Segment Anything (SAM) and DINOv2

Lightweight backbone (U-Net based)

Plug-and-play distillation blocks (low and high-level)

Generalized across multiple polyp datasets

Reduced training cost + improved segmentation performance

üß† Key Contributions

Two-stage knowledge distillation pipeline

Feature priors from foundation models

Low + high frequency information learning

Generalized Polyp Segmentation benchmark

üì¶ Code (coming soon!)

Full implementation of training scripts, evaluation, and pretrained weights will be updated shortly.
